{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment#4\n",
    "## Rhichard Koh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step-1: Import all library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step-2: Load the Diabetes Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "     Number of times pregnant  Plasma glucose concentration  \\\n0                           6                           148   \n1                           1                            85   \n2                           8                           183   \n3                           1                            89   \n4                           0                           137   \n..                        ...                           ...   \n763                        10                           101   \n764                         2                           122   \n765                         5                           121   \n766                         1                           126   \n767                         1                            93   \n\n     Diastolic blood pressure  Triceps skin fold thickness  \\\n0                          72                           35   \n1                          66                           29   \n2                          64                            0   \n3                          66                           23   \n4                          40                           35   \n..                        ...                          ...   \n763                        76                           48   \n764                        70                           27   \n765                        72                           23   \n766                        60                            0   \n767                        70                           31   \n\n     2-Hour serum insulin  Body mass index  Diabetes pedigree function  Age  \\\n0                       0             33.6                       0.627   50   \n1                       0             26.6                       0.351   31   \n2                       0             23.3                       0.672   32   \n3                      94             28.1                       0.167   21   \n4                     168             43.1                       2.288   33   \n..                    ...              ...                         ...  ...   \n763                   180             32.9                       0.171   63   \n764                     0             36.8                       0.340   27   \n765                   112             26.2                       0.245   30   \n766                     0             30.1                       0.349   47   \n767                     0             30.4                       0.315   23   \n\n     Class variable  \n0                 1  \n1                 0  \n2                 1  \n3                 0  \n4                 1  \n..              ...  \n763               0  \n764               0  \n765               0  \n766               1  \n767               0  \n\n[768 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Number of times pregnant</th>\n      <th>Plasma glucose concentration</th>\n      <th>Diastolic blood pressure</th>\n      <th>Triceps skin fold thickness</th>\n      <th>2-Hour serum insulin</th>\n      <th>Body mass index</th>\n      <th>Diabetes pedigree function</th>\n      <th>Age</th>\n      <th>Class variable</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>6</td>\n      <td>148</td>\n      <td>72</td>\n      <td>35</td>\n      <td>0</td>\n      <td>33.6</td>\n      <td>0.627</td>\n      <td>50</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>85</td>\n      <td>66</td>\n      <td>29</td>\n      <td>0</td>\n      <td>26.6</td>\n      <td>0.351</td>\n      <td>31</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8</td>\n      <td>183</td>\n      <td>64</td>\n      <td>0</td>\n      <td>0</td>\n      <td>23.3</td>\n      <td>0.672</td>\n      <td>32</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>89</td>\n      <td>66</td>\n      <td>23</td>\n      <td>94</td>\n      <td>28.1</td>\n      <td>0.167</td>\n      <td>21</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>137</td>\n      <td>40</td>\n      <td>35</td>\n      <td>168</td>\n      <td>43.1</td>\n      <td>2.288</td>\n      <td>33</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>763</th>\n      <td>10</td>\n      <td>101</td>\n      <td>76</td>\n      <td>48</td>\n      <td>180</td>\n      <td>32.9</td>\n      <td>0.171</td>\n      <td>63</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>764</th>\n      <td>2</td>\n      <td>122</td>\n      <td>70</td>\n      <td>27</td>\n      <td>0</td>\n      <td>36.8</td>\n      <td>0.340</td>\n      <td>27</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>765</th>\n      <td>5</td>\n      <td>121</td>\n      <td>72</td>\n      <td>23</td>\n      <td>112</td>\n      <td>26.2</td>\n      <td>0.245</td>\n      <td>30</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>766</th>\n      <td>1</td>\n      <td>126</td>\n      <td>60</td>\n      <td>0</td>\n      <td>0</td>\n      <td>30.1</td>\n      <td>0.349</td>\n      <td>47</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>767</th>\n      <td>1</td>\n      <td>93</td>\n      <td>70</td>\n      <td>31</td>\n      <td>0</td>\n      <td>30.4</td>\n      <td>0.315</td>\n      <td>23</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>768 rows Ã— 9 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('diabetes.csv', names=['Number of times pregnant','Plasma glucose concentration' ,'Diastolic blood pressure' ,'Triceps skin fold thickness' ,'2-Hour serum insulin' ,'Body mass index' ,'Diabetes pedigree function' ,'Age' ,'Class variable'])\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step-3: Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 0.93138344,  2.0179454 ,  0.78066953, ...,  0.43148259,\n        -0.37477883,  0.63212912],\n       [ 0.63260632, -1.14861888,  0.46538785, ..., -0.1198324 ,\n        -0.29416766,  0.71699246],\n       [-0.56250219, -0.47692343, -0.2702694 , ..., -0.20958135,\n         2.74517192,  0.03808578],\n       ...,\n       [-0.86127931, -0.76479291,  0.04501228, ...,  0.76483585,\n        -0.78380586, -0.30136756],\n       [ 0.63260632,  2.20985838,  1.2010451 , ...,  0.43148259,\n        -0.60466993,  2.75371249],\n       [ 0.03505207,  0.73852549, -0.58555107, ..., -0.33779414,\n        -0.57779954,  0.29267578]])"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop(columns=['Class variable'])\n",
    "y = df['Class variable']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.30, random_state=42, stratify=y)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "X_train_scaled"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step-4: Train a Keras Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a Neural Network model with 200 epochs and batch size of 16."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "34/34 [==============================] - 1s 4ms/step - loss: 0.6740 - accuracy: 0.6276 - val_loss: 13.9520 - val_accuracy: 0.6494\n",
      "Epoch 2/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.6432 - accuracy: 0.6443 - val_loss: 10.8458 - val_accuracy: 0.6494\n",
      "Epoch 3/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.6206 - accuracy: 0.6555 - val_loss: 8.1454 - val_accuracy: 0.6494\n",
      "Epoch 4/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.6023 - accuracy: 0.6555 - val_loss: 6.4489 - val_accuracy: 0.6494\n",
      "Epoch 5/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.5862 - accuracy: 0.6555 - val_loss: 4.4894 - val_accuracy: 0.6494\n",
      "Epoch 6/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.5721 - accuracy: 0.6648 - val_loss: 3.2711 - val_accuracy: 0.6190\n",
      "Epoch 7/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.5595 - accuracy: 0.6890 - val_loss: 2.7113 - val_accuracy: 0.6061\n",
      "Epoch 8/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.5465 - accuracy: 0.7095 - val_loss: 2.7493 - val_accuracy: 0.5455\n",
      "Epoch 9/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.5352 - accuracy: 0.7188 - val_loss: 3.9686 - val_accuracy: 0.3896\n",
      "Epoch 10/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.5252 - accuracy: 0.7356 - val_loss: 7.1928 - val_accuracy: 0.3723\n",
      "Epoch 11/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.5166 - accuracy: 0.7449 - val_loss: 9.9483 - val_accuracy: 0.3506\n",
      "Epoch 12/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.5070 - accuracy: 0.7542 - val_loss: 12.8796 - val_accuracy: 0.3506\n",
      "Epoch 13/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.4992 - accuracy: 0.7523 - val_loss: 15.1350 - val_accuracy: 0.3506\n",
      "Epoch 14/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.4914 - accuracy: 0.7542 - val_loss: 17.8659 - val_accuracy: 0.3506\n",
      "Epoch 15/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.4839 - accuracy: 0.7598 - val_loss: 20.8019 - val_accuracy: 0.3506\n",
      "Epoch 16/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.4777 - accuracy: 0.7616 - val_loss: 22.1379 - val_accuracy: 0.3506\n",
      "Epoch 17/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.4730 - accuracy: 0.7747 - val_loss: 24.3337 - val_accuracy: 0.3506\n",
      "Epoch 18/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.4685 - accuracy: 0.7747 - val_loss: 25.2655 - val_accuracy: 0.3506\n",
      "Epoch 19/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.4638 - accuracy: 0.7840 - val_loss: 26.1949 - val_accuracy: 0.3506\n",
      "Epoch 20/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.7877 - val_loss: 26.8034 - val_accuracy: 0.3506\n",
      "Epoch 21/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.4569 - accuracy: 0.7896 - val_loss: 28.2558 - val_accuracy: 0.3506\n",
      "Epoch 22/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.4539 - accuracy: 0.7840 - val_loss: 29.1294 - val_accuracy: 0.3506\n",
      "Epoch 23/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.4517 - accuracy: 0.7840 - val_loss: 30.0846 - val_accuracy: 0.3506\n",
      "Epoch 24/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.4498 - accuracy: 0.7821 - val_loss: 32.0230 - val_accuracy: 0.3506\n",
      "Epoch 25/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.4479 - accuracy: 0.7858 - val_loss: 32.0000 - val_accuracy: 0.3506\n",
      "Epoch 26/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.4459 - accuracy: 0.7840 - val_loss: 30.7817 - val_accuracy: 0.3506\n",
      "Epoch 27/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.4446 - accuracy: 0.7896 - val_loss: 32.5016 - val_accuracy: 0.3506\n",
      "Epoch 28/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.4427 - accuracy: 0.7840 - val_loss: 32.7911 - val_accuracy: 0.3506\n",
      "Epoch 29/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.4415 - accuracy: 0.7896 - val_loss: 33.7468 - val_accuracy: 0.3506\n",
      "Epoch 30/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.4400 - accuracy: 0.7952 - val_loss: 33.1959 - val_accuracy: 0.3506\n",
      "Epoch 31/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.4397 - accuracy: 0.7952 - val_loss: 34.2659 - val_accuracy: 0.3506\n",
      "Epoch 32/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.4370 - accuracy: 0.7914 - val_loss: 35.2077 - val_accuracy: 0.3506\n",
      "Epoch 33/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.4363 - accuracy: 0.7970 - val_loss: 33.8950 - val_accuracy: 0.3506\n",
      "Epoch 34/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.4356 - accuracy: 0.7933 - val_loss: 35.0282 - val_accuracy: 0.3506\n",
      "Epoch 35/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.4339 - accuracy: 0.7952 - val_loss: 36.4203 - val_accuracy: 0.3506\n",
      "Epoch 36/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.4330 - accuracy: 0.7896 - val_loss: 35.6026 - val_accuracy: 0.3506\n",
      "Epoch 37/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.4323 - accuracy: 0.7896 - val_loss: 37.2929 - val_accuracy: 0.3506\n",
      "Epoch 38/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.4311 - accuracy: 0.7877 - val_loss: 37.3461 - val_accuracy: 0.3506\n",
      "Epoch 39/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.4300 - accuracy: 0.7970 - val_loss: 36.3200 - val_accuracy: 0.3506\n",
      "Epoch 40/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.4296 - accuracy: 0.8007 - val_loss: 37.3683 - val_accuracy: 0.3506\n",
      "Epoch 41/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.4282 - accuracy: 0.7952 - val_loss: 39.3422 - val_accuracy: 0.3506\n",
      "Epoch 42/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.7952 - val_loss: 37.0108 - val_accuracy: 0.3506\n",
      "Epoch 43/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.4271 - accuracy: 0.7933 - val_loss: 38.4491 - val_accuracy: 0.3506\n",
      "Epoch 44/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.4263 - accuracy: 0.7914 - val_loss: 37.7719 - val_accuracy: 0.3506\n",
      "Epoch 45/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.4254 - accuracy: 0.7970 - val_loss: 39.6650 - val_accuracy: 0.3506\n",
      "Epoch 46/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.4244 - accuracy: 0.7970 - val_loss: 38.5166 - val_accuracy: 0.3506\n",
      "Epoch 47/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.4235 - accuracy: 0.7952 - val_loss: 40.3519 - val_accuracy: 0.3506\n",
      "Epoch 48/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.4233 - accuracy: 0.8007 - val_loss: 39.0852 - val_accuracy: 0.3506\n",
      "Epoch 49/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.4221 - accuracy: 0.7896 - val_loss: 40.7682 - val_accuracy: 0.3506\n",
      "Epoch 50/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.4210 - accuracy: 0.7952 - val_loss: 41.0301 - val_accuracy: 0.3506\n",
      "Epoch 51/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.4198 - accuracy: 0.7952 - val_loss: 41.8268 - val_accuracy: 0.3506\n",
      "Epoch 52/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.4194 - accuracy: 0.7952 - val_loss: 41.3481 - val_accuracy: 0.3506\n",
      "Epoch 53/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.4187 - accuracy: 0.7970 - val_loss: 42.7608 - val_accuracy: 0.3506\n",
      "Epoch 54/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.4171 - accuracy: 0.7952 - val_loss: 42.9444 - val_accuracy: 0.3506\n",
      "Epoch 55/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.4162 - accuracy: 0.7952 - val_loss: 43.4616 - val_accuracy: 0.3506\n",
      "Epoch 56/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.4161 - accuracy: 0.7952 - val_loss: 42.6952 - val_accuracy: 0.3506\n",
      "Epoch 57/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.4142 - accuracy: 0.7933 - val_loss: 43.8410 - val_accuracy: 0.3506\n",
      "Epoch 58/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.4142 - accuracy: 0.7952 - val_loss: 44.7377 - val_accuracy: 0.3506\n",
      "Epoch 59/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.4126 - accuracy: 0.7933 - val_loss: 45.0123 - val_accuracy: 0.3506\n",
      "Epoch 60/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.4120 - accuracy: 0.7952 - val_loss: 44.5449 - val_accuracy: 0.3506\n",
      "Epoch 61/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.4116 - accuracy: 0.7952 - val_loss: 45.4481 - val_accuracy: 0.3506\n",
      "Epoch 62/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.4108 - accuracy: 0.7952 - val_loss: 45.0813 - val_accuracy: 0.3506\n",
      "Epoch 63/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.4101 - accuracy: 0.7914 - val_loss: 45.2390 - val_accuracy: 0.3506\n",
      "Epoch 64/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.4093 - accuracy: 0.7933 - val_loss: 45.4520 - val_accuracy: 0.3506\n",
      "Epoch 65/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.4085 - accuracy: 0.7933 - val_loss: 45.8653 - val_accuracy: 0.3506\n",
      "Epoch 66/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.4080 - accuracy: 0.7970 - val_loss: 45.8792 - val_accuracy: 0.3506\n",
      "Epoch 67/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.4075 - accuracy: 0.7970 - val_loss: 45.7287 - val_accuracy: 0.3506\n",
      "Epoch 68/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.4061 - accuracy: 0.7952 - val_loss: 46.8089 - val_accuracy: 0.3506\n",
      "Epoch 69/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.4044 - accuracy: 0.8026 - val_loss: 46.4067 - val_accuracy: 0.3506\n",
      "Epoch 70/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.4045 - accuracy: 0.8007 - val_loss: 47.0041 - val_accuracy: 0.3506\n",
      "Epoch 71/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.4031 - accuracy: 0.7970 - val_loss: 47.8032 - val_accuracy: 0.3506\n",
      "Epoch 72/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.4027 - accuracy: 0.8045 - val_loss: 47.1379 - val_accuracy: 0.3506\n",
      "Epoch 73/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.4025 - accuracy: 0.7989 - val_loss: 47.4818 - val_accuracy: 0.3506\n",
      "Epoch 74/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.4009 - accuracy: 0.8026 - val_loss: 47.2720 - val_accuracy: 0.3506\n",
      "Epoch 75/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.4008 - accuracy: 0.8045 - val_loss: 48.8064 - val_accuracy: 0.3506\n",
      "Epoch 76/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.4004 - accuracy: 0.8045 - val_loss: 49.3547 - val_accuracy: 0.3506\n",
      "Epoch 77/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3995 - accuracy: 0.8026 - val_loss: 48.8821 - val_accuracy: 0.3506\n",
      "Epoch 78/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3981 - accuracy: 0.8045 - val_loss: 50.7191 - val_accuracy: 0.3506\n",
      "Epoch 79/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3973 - accuracy: 0.8045 - val_loss: 49.4062 - val_accuracy: 0.3506\n",
      "Epoch 80/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3965 - accuracy: 0.8082 - val_loss: 50.5974 - val_accuracy: 0.3506\n",
      "Epoch 81/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3973 - accuracy: 0.8026 - val_loss: 50.6690 - val_accuracy: 0.3506\n",
      "Epoch 82/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3952 - accuracy: 0.8063 - val_loss: 50.4760 - val_accuracy: 0.3506\n",
      "Epoch 83/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3948 - accuracy: 0.8063 - val_loss: 50.3491 - val_accuracy: 0.3506\n",
      "Epoch 84/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3943 - accuracy: 0.8063 - val_loss: 51.1337 - val_accuracy: 0.3506\n",
      "Epoch 85/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3937 - accuracy: 0.8063 - val_loss: 51.2061 - val_accuracy: 0.3506\n",
      "Epoch 86/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3927 - accuracy: 0.8063 - val_loss: 50.9057 - val_accuracy: 0.3506\n",
      "Epoch 87/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3923 - accuracy: 0.8063 - val_loss: 50.4497 - val_accuracy: 0.3506\n",
      "Epoch 88/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3916 - accuracy: 0.8082 - val_loss: 51.3138 - val_accuracy: 0.3506\n",
      "Epoch 89/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3912 - accuracy: 0.8101 - val_loss: 51.0346 - val_accuracy: 0.3506\n",
      "Epoch 90/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3897 - accuracy: 0.8082 - val_loss: 51.5477 - val_accuracy: 0.3506\n",
      "Epoch 91/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3886 - accuracy: 0.8063 - val_loss: 51.3290 - val_accuracy: 0.3506\n",
      "Epoch 92/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3878 - accuracy: 0.8082 - val_loss: 51.9837 - val_accuracy: 0.3506\n",
      "Epoch 93/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3881 - accuracy: 0.8082 - val_loss: 52.1961 - val_accuracy: 0.3506\n",
      "Epoch 94/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3870 - accuracy: 0.8063 - val_loss: 51.6155 - val_accuracy: 0.3506\n",
      "Epoch 95/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3860 - accuracy: 0.8063 - val_loss: 52.4296 - val_accuracy: 0.3506\n",
      "Epoch 96/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3859 - accuracy: 0.8156 - val_loss: 53.1704 - val_accuracy: 0.3506\n",
      "Epoch 97/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3844 - accuracy: 0.8101 - val_loss: 52.4335 - val_accuracy: 0.3506\n",
      "Epoch 98/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3836 - accuracy: 0.8101 - val_loss: 52.5610 - val_accuracy: 0.3506\n",
      "Epoch 99/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3838 - accuracy: 0.8138 - val_loss: 55.6855 - val_accuracy: 0.3506\n",
      "Epoch 100/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3820 - accuracy: 0.8138 - val_loss: 53.5597 - val_accuracy: 0.3506\n",
      "Epoch 101/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3824 - accuracy: 0.8082 - val_loss: 51.7017 - val_accuracy: 0.3506\n",
      "Epoch 102/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3813 - accuracy: 0.8082 - val_loss: 53.5199 - val_accuracy: 0.3506\n",
      "Epoch 103/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3801 - accuracy: 0.8119 - val_loss: 53.0277 - val_accuracy: 0.3506\n",
      "Epoch 104/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3799 - accuracy: 0.8082 - val_loss: 53.3885 - val_accuracy: 0.3506\n",
      "Epoch 105/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3786 - accuracy: 0.8156 - val_loss: 54.2658 - val_accuracy: 0.3506\n",
      "Epoch 106/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3784 - accuracy: 0.8156 - val_loss: 54.3505 - val_accuracy: 0.3506\n",
      "Epoch 107/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3772 - accuracy: 0.8156 - val_loss: 56.2169 - val_accuracy: 0.3506\n",
      "Epoch 108/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3779 - accuracy: 0.8212 - val_loss: 56.9926 - val_accuracy: 0.3506\n",
      "Epoch 109/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3759 - accuracy: 0.8156 - val_loss: 53.1675 - val_accuracy: 0.3506\n",
      "Epoch 110/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3749 - accuracy: 0.8175 - val_loss: 55.3623 - val_accuracy: 0.3506\n",
      "Epoch 111/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3742 - accuracy: 0.8212 - val_loss: 54.5781 - val_accuracy: 0.3506\n",
      "Epoch 112/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3736 - accuracy: 0.8119 - val_loss: 54.2023 - val_accuracy: 0.3506\n",
      "Epoch 113/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3726 - accuracy: 0.8212 - val_loss: 54.8593 - val_accuracy: 0.3506\n",
      "Epoch 114/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3718 - accuracy: 0.8175 - val_loss: 54.3582 - val_accuracy: 0.3506\n",
      "Epoch 115/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3726 - accuracy: 0.8175 - val_loss: 54.2120 - val_accuracy: 0.3506\n",
      "Epoch 116/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3708 - accuracy: 0.8175 - val_loss: 53.1975 - val_accuracy: 0.3506\n",
      "Epoch 117/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3708 - accuracy: 0.8250 - val_loss: 55.3464 - val_accuracy: 0.3506\n",
      "Epoch 118/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3692 - accuracy: 0.8194 - val_loss: 55.7276 - val_accuracy: 0.3506\n",
      "Epoch 119/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3689 - accuracy: 0.8231 - val_loss: 54.4614 - val_accuracy: 0.3506\n",
      "Epoch 120/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3679 - accuracy: 0.8268 - val_loss: 56.2280 - val_accuracy: 0.3506\n",
      "Epoch 121/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3677 - accuracy: 0.8231 - val_loss: 54.8946 - val_accuracy: 0.3506\n",
      "Epoch 122/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3672 - accuracy: 0.8250 - val_loss: 55.8890 - val_accuracy: 0.3506\n",
      "Epoch 123/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3662 - accuracy: 0.8250 - val_loss: 56.6649 - val_accuracy: 0.3506\n",
      "Epoch 124/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3656 - accuracy: 0.8212 - val_loss: 54.5445 - val_accuracy: 0.3506\n",
      "Epoch 125/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3657 - accuracy: 0.8268 - val_loss: 56.8832 - val_accuracy: 0.3506\n",
      "Epoch 126/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3641 - accuracy: 0.8231 - val_loss: 56.2771 - val_accuracy: 0.3506\n",
      "Epoch 127/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3633 - accuracy: 0.8250 - val_loss: 55.4759 - val_accuracy: 0.3506\n",
      "Epoch 128/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3628 - accuracy: 0.8212 - val_loss: 56.6038 - val_accuracy: 0.3506\n",
      "Epoch 129/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3614 - accuracy: 0.8231 - val_loss: 58.0143 - val_accuracy: 0.3506\n",
      "Epoch 130/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3614 - accuracy: 0.8268 - val_loss: 57.6925 - val_accuracy: 0.3506\n",
      "Epoch 131/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3606 - accuracy: 0.8268 - val_loss: 58.1532 - val_accuracy: 0.3506\n",
      "Epoch 132/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3600 - accuracy: 0.8305 - val_loss: 57.9575 - val_accuracy: 0.3506\n",
      "Epoch 133/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3591 - accuracy: 0.8268 - val_loss: 59.2181 - val_accuracy: 0.3506\n",
      "Epoch 134/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3596 - accuracy: 0.8343 - val_loss: 59.1648 - val_accuracy: 0.3506\n",
      "Epoch 135/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3574 - accuracy: 0.8268 - val_loss: 58.9512 - val_accuracy: 0.3506\n",
      "Epoch 136/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3568 - accuracy: 0.8231 - val_loss: 58.6265 - val_accuracy: 0.3506\n",
      "Epoch 137/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3565 - accuracy: 0.8324 - val_loss: 60.4358 - val_accuracy: 0.3506\n",
      "Epoch 138/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3550 - accuracy: 0.8324 - val_loss: 61.4855 - val_accuracy: 0.3506\n",
      "Epoch 139/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3552 - accuracy: 0.8268 - val_loss: 60.1803 - val_accuracy: 0.3506\n",
      "Epoch 140/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3558 - accuracy: 0.8250 - val_loss: 62.3981 - val_accuracy: 0.3506\n",
      "Epoch 141/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3541 - accuracy: 0.8305 - val_loss: 61.0331 - val_accuracy: 0.3506\n",
      "Epoch 142/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3531 - accuracy: 0.8324 - val_loss: 62.7166 - val_accuracy: 0.3506\n",
      "Epoch 143/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8287 - val_loss: 64.0170 - val_accuracy: 0.3506\n",
      "Epoch 144/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3521 - accuracy: 0.8343 - val_loss: 62.9014 - val_accuracy: 0.3506\n",
      "Epoch 145/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3516 - accuracy: 0.8250 - val_loss: 62.6888 - val_accuracy: 0.3506\n",
      "Epoch 146/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3499 - accuracy: 0.8287 - val_loss: 64.6946 - val_accuracy: 0.3506\n",
      "Epoch 147/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3508 - accuracy: 0.8361 - val_loss: 64.4654 - val_accuracy: 0.3506\n",
      "Epoch 148/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3498 - accuracy: 0.8343 - val_loss: 65.0156 - val_accuracy: 0.3506\n",
      "Epoch 149/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3487 - accuracy: 0.8361 - val_loss: 66.1432 - val_accuracy: 0.3506\n",
      "Epoch 150/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3494 - accuracy: 0.8324 - val_loss: 65.7403 - val_accuracy: 0.3506\n",
      "Epoch 151/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3475 - accuracy: 0.8361 - val_loss: 67.0854 - val_accuracy: 0.3506\n",
      "Epoch 152/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3464 - accuracy: 0.8417 - val_loss: 67.8388 - val_accuracy: 0.3506\n",
      "Epoch 153/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3458 - accuracy: 0.8399 - val_loss: 67.2784 - val_accuracy: 0.3506\n",
      "Epoch 154/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3451 - accuracy: 0.8380 - val_loss: 67.1763 - val_accuracy: 0.3506\n",
      "Epoch 155/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3453 - accuracy: 0.8361 - val_loss: 68.1697 - val_accuracy: 0.3506\n",
      "Epoch 156/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3448 - accuracy: 0.8417 - val_loss: 69.2268 - val_accuracy: 0.3506\n",
      "Epoch 157/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3439 - accuracy: 0.8436 - val_loss: 69.0334 - val_accuracy: 0.3506\n",
      "Epoch 158/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3449 - accuracy: 0.8361 - val_loss: 71.0836 - val_accuracy: 0.3506\n",
      "Epoch 159/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3436 - accuracy: 0.8436 - val_loss: 68.3956 - val_accuracy: 0.3506\n",
      "Epoch 160/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3413 - accuracy: 0.8473 - val_loss: 70.9392 - val_accuracy: 0.3506\n",
      "Epoch 161/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3414 - accuracy: 0.8417 - val_loss: 69.9867 - val_accuracy: 0.3506\n",
      "Epoch 162/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3413 - accuracy: 0.8454 - val_loss: 72.0313 - val_accuracy: 0.3506\n",
      "Epoch 163/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3397 - accuracy: 0.8473 - val_loss: 73.2024 - val_accuracy: 0.3506\n",
      "Epoch 164/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3404 - accuracy: 0.8399 - val_loss: 72.5535 - val_accuracy: 0.3506\n",
      "Epoch 165/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3388 - accuracy: 0.8473 - val_loss: 73.2218 - val_accuracy: 0.3506\n",
      "Epoch 166/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3386 - accuracy: 0.8492 - val_loss: 74.8942 - val_accuracy: 0.3506\n",
      "Epoch 167/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3375 - accuracy: 0.8454 - val_loss: 73.1201 - val_accuracy: 0.3506\n",
      "Epoch 168/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3373 - accuracy: 0.8436 - val_loss: 75.1616 - val_accuracy: 0.3506\n",
      "Epoch 169/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3372 - accuracy: 0.8436 - val_loss: 73.3945 - val_accuracy: 0.3506\n",
      "Epoch 170/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3361 - accuracy: 0.8436 - val_loss: 75.1271 - val_accuracy: 0.3506\n",
      "Epoch 171/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3353 - accuracy: 0.8436 - val_loss: 73.8143 - val_accuracy: 0.3506\n",
      "Epoch 172/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3355 - accuracy: 0.8473 - val_loss: 75.7842 - val_accuracy: 0.3506\n",
      "Epoch 173/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3334 - accuracy: 0.8473 - val_loss: 76.2399 - val_accuracy: 0.3506\n",
      "Epoch 174/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3338 - accuracy: 0.8547 - val_loss: 76.4369 - val_accuracy: 0.3506\n",
      "Epoch 175/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3325 - accuracy: 0.8454 - val_loss: 76.3631 - val_accuracy: 0.3506\n",
      "Epoch 176/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3323 - accuracy: 0.8510 - val_loss: 77.4805 - val_accuracy: 0.3506\n",
      "Epoch 177/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3318 - accuracy: 0.8547 - val_loss: 77.8726 - val_accuracy: 0.3506\n",
      "Epoch 178/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3308 - accuracy: 0.8529 - val_loss: 77.7995 - val_accuracy: 0.3506\n",
      "Epoch 179/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3305 - accuracy: 0.8529 - val_loss: 79.0166 - val_accuracy: 0.3506\n",
      "Epoch 180/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3290 - accuracy: 0.8510 - val_loss: 78.9151 - val_accuracy: 0.3506\n",
      "Epoch 181/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3297 - accuracy: 0.8492 - val_loss: 79.4618 - val_accuracy: 0.3506\n",
      "Epoch 182/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3282 - accuracy: 0.8547 - val_loss: 82.3918 - val_accuracy: 0.3506\n",
      "Epoch 183/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3291 - accuracy: 0.8473 - val_loss: 80.9669 - val_accuracy: 0.3506\n",
      "Epoch 184/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3271 - accuracy: 0.8547 - val_loss: 82.5247 - val_accuracy: 0.3506\n",
      "Epoch 185/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3263 - accuracy: 0.8585 - val_loss: 82.4697 - val_accuracy: 0.3506\n",
      "Epoch 186/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3262 - accuracy: 0.8566 - val_loss: 83.0573 - val_accuracy: 0.3506\n",
      "Epoch 187/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3257 - accuracy: 0.8566 - val_loss: 85.5975 - val_accuracy: 0.3506\n",
      "Epoch 188/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3248 - accuracy: 0.8566 - val_loss: 82.9622 - val_accuracy: 0.3506\n",
      "Epoch 189/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3250 - accuracy: 0.8510 - val_loss: 84.2583 - val_accuracy: 0.3506\n",
      "Epoch 190/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3243 - accuracy: 0.8585 - val_loss: 87.0577 - val_accuracy: 0.3506\n",
      "Epoch 191/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3235 - accuracy: 0.8603 - val_loss: 86.9834 - val_accuracy: 0.3506\n",
      "Epoch 192/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3221 - accuracy: 0.8566 - val_loss: 88.0551 - val_accuracy: 0.3506\n",
      "Epoch 193/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3251 - accuracy: 0.8529 - val_loss: 85.3425 - val_accuracy: 0.3506\n",
      "Epoch 194/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3213 - accuracy: 0.8585 - val_loss: 91.0269 - val_accuracy: 0.3506\n",
      "Epoch 195/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3205 - accuracy: 0.8603 - val_loss: 87.6886 - val_accuracy: 0.3506\n",
      "Epoch 196/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3203 - accuracy: 0.8622 - val_loss: 87.6072 - val_accuracy: 0.3506\n",
      "Epoch 197/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3197 - accuracy: 0.8566 - val_loss: 88.9409 - val_accuracy: 0.3506\n",
      "Epoch 198/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3190 - accuracy: 0.8622 - val_loss: 90.5889 - val_accuracy: 0.3506\n",
      "Epoch 199/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3200 - accuracy: 0.8585 - val_loss: 91.0532 - val_accuracy: 0.3506\n",
      "Epoch 200/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 0.3181 - accuracy: 0.8603 - val_loss: 92.0617 - val_accuracy: 0.3506\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_17 (Dense)            (None, 12)                108       \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 221\n",
      "Trainable params: 221\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential(\n",
    "    [\n",
    "        Dense(12, input_dim=X.shape[1], activation='relu'),\n",
    "        Dense(8, activation='relu'),\n",
    "        Dense(1, activation='sigmoid'),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train_scaled, y_train, validation_data=(X_val, y_val), epochs=200, batch_size=16)\n",
    "\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 576x360 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5),  xlim=[0, 200], ylim=[0, 2.5], grid=True, xlabel=\"Epoch\", style=[\"r--\", \"r--.\", \"b-\", \"b-*\"])\n",
    "\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step-5: Make prediction on data point [[6,148,72,35,0,33.6,0.627,50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 37ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xxryk\\anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "[1]"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [[6,148,72,35,0,33.6,0.627,50]]\n",
    "data_scaled = scaler.transform(data)\n",
    "\n",
    "data_prediction = model.predict(data_scaled)\n",
    "data_prediction = [1 if i > 0.5 else 0 for i in data_prediction]\n",
    "data_prediction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
